{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Outlook Temperature Humidity    Wind Play Tennis\n",
      "0      Sunny         Hot     High    Weak          no\n",
      "1      Sunny         Hot     High  Strong          no\n",
      "2   Overcast         Hot     High    Weak         yes\n",
      "3       Rain        Mild     High    Weak         yes\n",
      "4       Rain        Cool   Normal    Weak         yes\n",
      "5       Rain        Cool   Normal  Strong          no\n",
      "6   Overcast        Cool   Normal  Strong         yes\n",
      "7      Sunny        Mild     High    Weak          no\n",
      "8      Sunny        Cool   Normal    Weak         yes\n",
      "9       Rain        Mild   Normal    Weak         yes\n",
      "10     Sunny        Mild   Normal  Strong         yes\n",
      "11  Overcast        Mild     High  Strong         yes\n",
      "12  Overcast         Hot   Normal    Weak         yes\n",
      "13      Rain        Mild     High  Strong          no\n",
      "{'Temperature': {'Mild': {'Outlook': {'Sunny': {'Humidity': {'Normal': 'yes'}}}}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "eps = np.finfo(float).eps\n",
    "data=pd.read_csv(\"PlayTennis.csv\")\n",
    "print(data)\n",
    "\n",
    "# Entropy of the target attribute values\n",
    "def find_entropy(df):\n",
    "  target = df.keys()[-1]\n",
    "  # The last dataframe column is the target attribute (playGolf)\n",
    "  entropy =0\n",
    "  values = df[target].unique()\n",
    "  # for each value in the target playGolf attribute values\n",
    "  for value in values:\n",
    "    # ratio of values occurring and entropy\n",
    "    fraction = df[target].value_counts()[value] / len(df[target])\n",
    "    entropy += -fraction * np.log2(fraction)\n",
    "  return entropy\n",
    "  \n",
    "# Entropy of attribute values\n",
    "def find_entropy_attribute(df,attribute):\n",
    "  target = df.keys()[-1]\n",
    "  target_variables = df[target].unique()\n",
    "  # unique values in target playGolf attribute (Y\n",
    "  variables = df[attribute].unique()\n",
    "  # Identify Sunny, Overcast, Rainy\n",
    "  # attribute entropy # Variables=[sunny, sunny....5, overcast1.....overcast4,\n",
    "  entropy2 = 0\n",
    "  # for each attribute value in attribute values\n",
    "  for variable in variables:\n",
    "    # value entropy\n",
    "    entropy = 0\n",
    "  # for each target value in target values (yes/no)\n",
    "  for target_variable in target_variables:\n",
    "    # frequency of attribute and target values (boolean indexing, pandas dataframe\n",
    "    num = len(df[attribute][df[attribute] == variable][df[target] == target_variable])\n",
    "    den = len(df[attribute][df[attribute] == variable])\n",
    "    fraction = num / (den + eps)\n",
    "    entropy += -fraction * np.log2(fraction + eps)\n",
    "  fraction2 = den /len(df)\n",
    "  entropy2 += -fraction2 * entropy\n",
    "  return abs(entropy2)\n",
    "  #return abs(entropy)\n",
    "\n",
    "def bestClassifier(df):\n",
    "  # Entropy_att = []\n",
    "  # information gain array for all attributes\n",
    "  IG = []\n",
    "  # for all attributes excluding target\n",
    "  for key in df.keys()[:-1]:\n",
    "    # Entropy_att.append(find_entropy_attribute(df,key))\n",
    "    # calculate and record information gain value\n",
    "    IG.append(find_entropy(df) - find_entropy_attribute(df, key))\n",
    "  #0.940 -0.693= 0.247\n",
    "  return df.keys()[:-1][np.argmax(IG)]\n",
    "  # IG[0.247, 0.029, 0.152, 0.048 ]\n",
    "\n",
    "def get_subtable(df,node,value):\n",
    "  return df[df[node] == value].reset_index(drop=True)\n",
    "\n",
    "def ID3split(df, tree=None):\n",
    "  target = df.keys()[-1]\n",
    "  # Here we build our decision tree\n",
    "  # Get attribute with maximum information gain\n",
    "  node = bestClassifier(df) # 0.247\n",
    "  # Get distinct value of that attribute e.g Salary is node and Low,Med and High are val\n",
    "  attributeValues = np.unique(df[node])\n",
    "  # Create an empty dictionary to create tree (recursive-friendly definition)\n",
    "  if tree is None: # Outlook ->root node attribute\n",
    "    tree = {}\n",
    "    tree[node] = {}\n",
    "  # following loop recursively calls ID3split to create and add to the tree\n",
    "  # it runs till the tree is pure (leaf (result) node branches are added to the tree)\n",
    "  for value in attributeValues:\n",
    "    # get the subtable from current node based on the value\n",
    "    subtable = get_subtable(df, node, value)\n",
    "    # get the most common target value in the subtable\n",
    "    targetValues, counts = np.unique(subtable[target], return_counts=True)\n",
    "  # if the subtable is empty, assign the leaf node to the most common target value\n",
    "  if len(counts) == 1:\n",
    "    tree[node][value] = targetValues[0]\n",
    "  else:\n",
    "    # recursively call ID3 to create subtrees\n",
    "    tree[node][value] = ID3split(subtable) # Calling the function recursively\n",
    "  return tree\n",
    "\n",
    "decisionTree = ID3split(data)\n",
    "print(decisionTree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae98a2d7cb2d0c57cfbbd7d812947b84707417a4702cc81eb8890c9224ec2f85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
